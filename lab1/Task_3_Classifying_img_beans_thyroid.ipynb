{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCE 5380 Spring 2018 - Data Mining - Lab Assignment 1 - Task 3\n",
    "\n",
    "Constant Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Index<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Image-Segmentation-Data\" data-toc-modified-id=\"Image-Segmentation-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Image Segmentation Data</a></span></li><li><span><a href=\"#Large-Soybean-Database\" data-toc-modified-id=\"Large-Soybean-Database-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Large Soybean Database</a></span></li><li><span><a href=\"#Thyroid-Disease-Records\" data-toc-modified-id=\"Thyroid-Disease-Records-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Thyroid Disease Records</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Problem-5:-Error-rate-and-accuracy-for-each-of-the-datasets\" data-toc-modified-id=\"Problem-5:-Error-rate-and-accuracy-for-each-of-the-datasets-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Problem 5: Error-rate and accuracy for each of the datasets</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Decision Tree classifier on [Image Segmentation data](data/segment.arff), [Large Soybean Database](data/soybean.arff), and [Thyroid disease records](data/sick.arff) with a 72% and 28% split of training and test data respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Image Segmentation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Import the image segment dataset, display the first record, and the number of records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "format": "row",
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 218.,  178.,  9.,  0.111111,  0.,  0.833333,  0.547722,  1.11111,  0.544331,  59.6296,  52.4444,  75.2222,  51.2222, -21.5556,  46.7778, -25.2222,  75.2222,  0.318996, -2.04055, b'path') \n",
      "\n",
      "There are 2310 records. \n"
     ]
    }
   ],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "with open(\"data/segment.arff\", \"r\") as f:\n",
    "    data, meta = loadarff(f)\n",
    "print(data[0],'\\n')\n",
    "print('There are %d records. ' % (data.size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Slice out the feature set and save as numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "format": "row",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.18000000e+02   1.78000000e+02   9.00000000e+00   1.11111000e-01\n",
      "   0.00000000e+00   8.33333000e-01   5.47722000e-01   1.11111000e+00\n",
      "   5.44331000e-01   5.96296000e+01   5.24444000e+01   7.52222000e+01\n",
      "   5.12222000e+01  -2.15556000e+01   4.67778000e+01  -2.52222000e+01\n",
      "   7.52222000e+01   3.18996000e-01  -2.04055000e+00]\n"
     ]
    }
   ],
   "source": [
    "X = data[meta.names()[0:-1]]\n",
    "import numpy as np\n",
    "X = np.asarray(X.tolist())\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Slice out the class data, save as numpy array, identify the unique classes, and display the number of classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "format": "row",
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'brickface' b'cement' b'foliage' b'grass' b'path' b'sky' b'window']\n",
      "\n",
      "There are 7 classes.\n"
     ]
    }
   ],
   "source": [
    "y = data[meta.names()[-1]]\n",
    "y = np.asarray(y.tolist())\n",
    "print(np.unique(y))\n",
    "print('\\nThere are %d classes.' %(np.size(np.unique(y))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Split the dataset into test and training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Splitting data into test and training set choosing a 10% sample Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create and train the model, count the nodes, display the tree with graphviz, create the confusion matrix, and use k-fold cross validation to calculate the accuracy and error rates.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 82   1   1   0   0   0   0]\n",
      " [  0  80   0   0   1   0   3]\n",
      " [  1   1  79   0   0   0   2]\n",
      " [  0   0   0 103   0   0   1]\n",
      " [  0   1   0   0  79   0   0]\n",
      " [  0   0   0   0   0 102   0]\n",
      " [  0   1   9   0   0   0 100]]\n",
      "\n",
      "Decision Tree (127 leaves) Accuracy on Segment Data: 0.95 (+/- 0.02)\n",
      "Decision Tree (127 leaves) Error on Segment Data: 0.05 (+/- 0.02)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Building the Model\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "leaves = classifier.tree_.node_count\n",
    "export_graphviz(classifier, out_file = 'graphs/segment_tree.dot')\n",
    "\n",
    "# Viewing the Tree \n",
    "import graphviz \n",
    "graphviz.view('graphs/segment_tree.dot')\n",
    "\n",
    "# Predictinging the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the Accuracy \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores= cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "errors = 1-scores\n",
    "print(cm)\n",
    "print(\"\\nDecision Tree (%d leaves) Accuracy on Segment Data: %0.2f (+/- %0.2f)\" % (leaves, scores.mean(), scores.std() * 2))\n",
    "print(\"Decision Tree (%d leaves) Error on Segment Data: %0.2f (+/- %0.2f)\\n\" % (leaves, errors.mean(), errors.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Large Soybean Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Import the image segment dataset, display the first record, and the number of records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'october', b'normal', b'gt-norm', b'norm', b'yes', b'same-lst-yr', b'low-areas', b'pot-severe', b'none', b'90-100', b'abnorm', b'abnorm', b'absent', b'dna', b'dna', b'absent', b'absent', b'absent', b'abnorm', b'no', b'above-sec-nde', b'brown', b'present', b'firm-and-dry', b'absent', b'none', b'absent', b'norm', b'dna', b'norm', b'absent', b'absent', b'norm', b'absent', b'norm', b'diaporthe-stem-canker') \n",
      "\n",
      "There are 683 records: \n"
     ]
    }
   ],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "with open(\"data/soybean.arff\", \"r\") as f:\n",
    "    data, meta = loadarff(f)\n",
    "print(data[0],'\\n')\n",
    "print('There are %d records: ' % (data.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Slice out the feature set, save as numpy array, and encode the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'october' b'normal' b'gt-norm' b'norm' b'yes' b'same-lst-yr' b'low-areas'\n",
      " b'pot-severe' b'none' b'90-100' b'abnorm' b'abnorm' b'absent' b'dna'\n",
      " b'dna' b'absent' b'absent' b'absent' b'abnorm' b'no' b'above-sec-nde'\n",
      " b'brown' b'present' b'firm-and-dry' b'absent' b'none' b'absent' b'norm'\n",
      " b'dna' b'norm' b'absent' b'absent' b'norm' b'absent' b'norm']\n",
      "[[6 2 1 3 2 4 1 2 2 1 1 0 1 1 1 1 1 1 1 1 1 1 2 2 1 3 1 4 4 2 1 1 2 1 2]\n",
      " [2 2 1 3 2 3 2 3 1 0 1 0 1 1 1 1 1 1 1 2 1 1 2 2 1 3 1 4 4 2 1 1 2 1 2]\n",
      " [3 2 1 3 2 4 2 3 1 3 1 0 1 1 1 1 1 1 1 2 1 3 2 2 1 3 1 4 4 2 1 1 2 1 2]\n",
      " [3 2 1 3 2 4 2 3 2 0 1 0 1 1 1 1 1 1 1 2 1 3 2 2 1 3 1 4 4 2 1 1 2 1 2]\n",
      " [6 2 1 3 2 3 2 2 2 3 1 0 1 1 1 1 1 1 1 2 1 1 2 2 1 3 1 4 4 2 1 1 2 1 2]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data[meta.names()[0:-1]]\n",
    "import numpy as np\n",
    "X = np.asarray(X.tolist())\n",
    "print(X[0])\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "for i in range(np.shape(X)[1]):\n",
    "    X[:,i] = labelencoder_X.fit_transform(X[:, i])\n",
    "X = X.astype(int)\n",
    "print(X[0:5],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Slice out the class data, save as numpy array, identify the unique classes, and display the number of classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'2-4-d-injury' b'alternarialeaf-spot' b'anthracnose' b'bacterial-blight'\n",
      " b'bacterial-pustule' b'brown-spot' b'brown-stem-rot' b'charcoal-rot'\n",
      " b'cyst-nematode' b'diaporthe-pod-&-stem-blight' b'diaporthe-stem-canker'\n",
      " b'downy-mildew' b'frog-eye-leaf-spot' b'herbicide-injury'\n",
      " b'phyllosticta-leaf-spot' b'phytophthora-rot' b'powdery-mildew'\n",
      " b'purple-seed-stain' b'rhizoctonia-root-rot']\n",
      "\n",
      "There are 19 classes\n"
     ]
    }
   ],
   "source": [
    "y = data[meta.names()[-1]]\n",
    "y = np.asarray(y.tolist())\n",
    "print(np.unique(y))\n",
    "print('\\nThere are %d classes' %(np.size(np.unique(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Split the dataset into test and training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Splitting data into test and training set choosing a 10% sample Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create and train the model, count the nodes, display the tree with graphviz, create the confusion matrix, and use k-fold cross validation to calculate the accuracy and error rates.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 30  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0 16  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 18  0  0  0  0  0  0  1  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0]\n",
      " [ 0  6  0  0  0  1  0  0  0  0  0  0 19  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  1  0  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  4  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  5]]\n",
      "\n",
      "Decision Tree (121 leaves) Accuracy on Soybean Data: 0.90 (+/- 0.04)\n",
      "Decision Tree (121 leaves) Error on Soybean Data: 0.05 (+/- 0.02)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Building the Model\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "leaves = classifier.tree_.node_count\n",
    "export_graphviz(classifier, out_file = 'graphs/soybean_tree.dot')\n",
    "\n",
    "# Viewing the Tree \n",
    "import graphviz \n",
    "graphviz.view('graphs/soybean_tree.dot')\n",
    "\n",
    "# Predictinging the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the Accuracy \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores= cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "print(cm)\n",
    "print(\"\\nDecision Tree (%d leaves) Accuracy on Soybean Data: %0.2f (+/- %0.2f)\" % (leaves, scores.mean(), scores.std() * 2))\n",
    "print(\"Decision Tree (%d leaves) Error on Soybean Data: %0.2f (+/- %0.2f)\\n\" % (leaves, errors.mean(), errors.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Thyroid Disease Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 41., b'F', b'f', b'f', b'f', b'f', b'f', b'f', b'f', b'f', b'f', b'f', b'f', b'f', b'f', b'f', b't',  1.3, b't',  2.5, b't',  125., b't',  1.14, b't',  109., b'f',  nan, b'SVHC', b'negative') \n",
      "\n",
      "There are 3772 records: \n"
     ]
    }
   ],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "with open(\"data/sick.arff\", \"r\") as f:\n",
    "    data, meta = loadarff(f)\n",
    "print(data[0],'\\n')\n",
    "print('There are %d records: ' % (data.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Slice out the feature set, save as numpy array, and encode the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'41.0' b'F' b'f' b'f' b'f' b'f' b'f' b'f' b'f' b'f' b'f' b'f' b'f' b'f'\n",
      " b'f' b'f' b't' b'1.3' b't' b'2.5' b't' b'125.0' b't' b'1.14' b't' b'109.0'\n",
      " b'f' b'nan' b'SVHC']\n",
      "[[ 34   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1 110\n",
      "    1  27   1  28   1  72   1  10   0   0   1]\n",
      " [ 15   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1 195\n",
      "    1  22   1   3   0 146   0 234   0   0   4]\n",
      " [ 40   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1 103\n",
      "    0  69   1  10   1  48   1  22   0   0   4]\n",
      " [ 67   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1  21\n",
      "    1  20   1  83   0 146   0 234   0   0   4]\n",
      " [ 67   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1  77\n",
      "    1  12   1 201   1  44   1 199   0   0   3]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data[meta.names()[0:-1]]\n",
    "import numpy as np\n",
    "X = np.asarray(X.tolist())\n",
    "print(X[0])\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "for i in range(np.shape(X)[1]):\n",
    "    X[:,i] = labelencoder_X.fit_transform(X[:, i])\n",
    "X = X.astype(int)\n",
    "print(X[0:5],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Slice out the class data, save as numpy array, identify the unique classes, and display the number of classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'negative' b'sick']\n",
      "\n",
      "There are 2 classes\n"
     ]
    }
   ],
   "source": [
    "y = data[meta.names()[-1]]\n",
    "y = np.asarray(y.tolist())\n",
    "print(np.unique(y))\n",
    "print('\\nThere are %d classes' %(np.size(np.unique(y))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Split the dataset into test and training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Splitting data into test and training set choosing a 10% sample Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create and train the model, count the nodes, display the tree with graphviz, create the confusion matrix, and use k-fold cross validation to calculate the accuracy and error rates.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[984  11]\n",
      " [  9  53]]\n",
      "\n",
      "Decision Tree (127 leaves) Accuracy on Thyroid Disease Data: 0.98 (+/- 0.00)\n",
      "\n",
      "Decision Tree (127 leaves) Error on Thyroid Disease Data: 0.05 (+/- 0.02)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Building the Model\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "leaves = classifier.tree_.node_count\n",
    "export_graphviz(classifier, out_file = 'graphs/sick_tree.dot')\n",
    "\n",
    "# Viewing the Tree \n",
    "import graphviz \n",
    "graphviz.view('graphs/sick_tree.dot')\n",
    "\n",
    "# Predictinging the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the Accuracy \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores= cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "print(cm)\n",
    "print(\"\\nDecision Tree (%d leaves) Accuracy on Thyroid Disease Data: %0.2f (+/- %0.2f)\\n\" % (leaves, scores.mean(), scores.std() * 2))\n",
    "print(\"Decision Tree (%d leaves) Error on Thyroid Disease Data: %0.2f (+/- %0.2f)\\n\" % (leaves, errors.mean(), errors.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Problem 5: Error-rate and accuracy for each of the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Calculate and report the error-rate and accuracy for each of the datasets. Which of the 3 datasets has the highest number of correctly classified instances?\n",
    "\n",
    "   **Answer:** \n",
    "   \n",
    "    Decision Tree (125 leaves) Accuracy Rate on Segment Data: 0.96 (+/- 0.02)\n",
    "    Decision Tree (125 leaves) Error Rate on Segment Data: 0.04 (+/- 0.02)\n",
    "\n",
    "    Decision Tree (131 leaves) Accuracy Rate on Soybean Data: 0.92 (+/- 0.07)\n",
    "    Decision Tree (131 leaves) Error Rate on Soybean Data: 0.04 (+/- 0.02)\n",
    "\n",
    "    Decision Tree (103 leaves) Accuracy on Thyroid Disease Data: 0.98 (+/- 0.01)\n",
    "    Decision Tree (103 leaves) Error on Thyroid Disease Data: 0.04 (+/- 0.02)\n",
    "    \n",
    "    The Thyroid Disease dateset has the highest accuracy rate. \n",
    "\n",
    "\n",
    "\n",
    "Which of the three datasets has the smallest and largest decision trees? Explain why you think the size of the decision trees varies.\n",
    "\n",
    "   **Answer**\n",
    "   \n",
    "   The size of the decision tree is proportional to the number of classes. The soybean dataset had the largest decision tree(131 nodes/leaves) as well as the largest number of classes (19).  The image segment dataset had the next largest tree(125 nodes/leaves) and 7 classes.  The Thyroid disease set had a binary class and the smallest tree size(103 nodes/leaves)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {
    "height": "87px",
    "width": "464px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Index",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 555,
   "position": {
    "height": "577px",
    "left": "1165px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
